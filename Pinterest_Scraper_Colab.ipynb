{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title"
      },
      "source": [
        "# Pinterest Multi-Topic Scraper - Google Colab Edition\n",
        "\n",
        "This notebook scrapes Pinterest images and saves them directly to your Google Drive.\n",
        "\n",
        "## Features:\n",
        "- Scrapes 300+ aesthetic topics across 17 categories\n",
        "- Saves directly to Google Drive (no upload needed)\n",
        "- NSFW filtering\n",
        "- Organized by category and topic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "## 1. Mount Google Drive\n",
        "\n",
        "This will mount your Google Drive to `/content/drive`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mount_drive"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "install_deps"
      },
      "source": [
        "## 2. Install Dependencies\n",
        "\n",
        "This may take 2-3 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install"
      },
      "outputs": [],
      "source": [
        "# Install Python packages\n",
        "!pip install -q playwright aiohttp python-dotenv\n",
        "\n",
        "# Install Playwright browsers\n",
        "!playwright install --with-deps chromium\n",
        "\n",
        "print(\"✓ Dependencies installed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "create_files"
      },
      "source": [
        "## 3. Create Project Files\n",
        "\n",
        "We'll create the necessary files in a temporary directory and run the scraper from there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup_files"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Create working directory in Colab\n",
        "WORK_DIR = Path('/content/pinterest_scraper')\n",
        "WORK_DIR.mkdir(exist_ok=True)\n",
        "os.chdir(WORK_DIR)\n",
        "\n",
        "print(f\"Working directory: {WORK_DIR}\")\n",
        "print(f\"✓ Ready to create project files\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_topics"
      },
      "outputs": [],
      "source": [
        "# Create topics.py\n",
        "topics_content = '''\n",
        "\"\"\"Pinterest topics organized by category.\"\"\"\n",
        "\n",
        "PINTEREST_TOPICS = {\n",
        "    \"STUDY_ACADEMIA\": [\n",
        "        \"dark academia\", \"light academia\", \"chaotic academia\", \"studytok\", \"study motivation\",\n",
        "        \"studygram\", \"coffee shop study\", \"library aesthetic\", \"desk organization\",\n",
        "        \"handwritten notes\", \"vintage university\", \"note-taking aesthetic\", \"study with me\",\n",
        "        \"bookshelf organization\", \"academic weapon\", \"productive morning\", \"study space\",\n",
        "        \"lecture hall vibes\", \"fountain pen aesthetic\", \"bullet journal study\", \"study aesthetic\",\n",
        "    ],\n",
        "    \"FOOD_COOKING\": [\n",
        "        \"healthy food aesthetic\", \"smoothie bowl\", \"matcha aesthetic\", \"granola girl\",\n",
        "        \"breakfast table\", \"cottage core food\", \"farmers market haul\", \"meal prep aesthetic\",\n",
        "        \"baking aesthetic\", \"homemade bread\", \"pasta making\", \"salad bowls\", \"coffee aesthetic\",\n",
        "        \"farmers daughter\", \"clean eating\", \"grocery haul aesthetic\", \"kitchen organization\",\n",
        "        \"vintage cookbook\", \"recipe cards\", \"sourdough aesthetic\", \"picnic spread\",\n",
        "        \"fruit arrangement\", \"cheese board aesthetic\",\n",
        "    ],\n",
        "    \"BOOKS_READING\": [\n",
        "        \"bookstok\", \"book and coffee\", \"reading nook\", \"annotated books\", \"bookshelf aesthetic\",\n",
        "        \"vintage library\", \"poetry aesthetic\", \"bookstore vibes\", \"antique books\",\n",
        "        \"leather-bound books\", \"reading by candlelight\", \"book stack\", \"bookworm aesthetic\",\n",
        "        \"cozy reading corner\", \"book haul\", \"current reads\", \"reading journal\", \"literary quotes\",\n",
        "        \"used bookstore\", \"book photography\", \"old book aesthetic\",\n",
        "    ],\n",
        "    \"TRAVEL\": [\n",
        "        \"European summer\", \"coastal grandmother\", \"Italian summer\", \"Greek island aesthetic\",\n",
        "        \"Paris aesthetic\", \"cobblestone streets\", \"train travel\", \"airport aesthetic\",\n",
        "        \"travel journal\", \"vintage luggage\", \"cafe hopping\", \"architecture photography\",\n",
        "        \"city walking\", \"countryside aesthetic\", \"road trip vibes\", \"mountain views\",\n",
        "        \"beach sunset\", \"travel outfit\", \"wanderlust aesthetic\", \"hidden gems\", \"local market\",\n",
        "        \"street photography\", \"travel aesthetic\",\n",
        "    ],\n",
        "    \"FITNESS_WELLNESS\": [\n",
        "        \"clean girl aesthetic\", \"pilates princess\", \"gym aesthetic\", \"yoga flow\", \"morning run\",\n",
        "        \"workout motivation\", \"athletic aesthetic\", \"gym fits\", \"activewear\", \"stretching routine\",\n",
        "        \"pilates studio\", \"home workout\", \"fitness journey\", \"healthy habits\", \"self care routine\",\n",
        "        \"wellness aesthetic\", \"mindful movement\", \"runner girl\", \"gym selfie\", \"workout mirror\",\n",
        "        \"fitness aesthetic\",\n",
        "    ],\n",
        "    \"NATURE_OUTDOORS\": [\n",
        "        \"cottage core\", \"forest bathing\", \"hiking aesthetic\", \"sunrise walks\", \"flower fields\",\n",
        "        \"botanical garden\", \"plant mom\", \"gardening aesthetic\", \"nature photography\", \"wildflowers\",\n",
        "        \"autumn leaves\", \"coastal walks\", \"mountain hiking\", \"camping aesthetic\", \"stargazing\",\n",
        "        \"nature journaling\", \"foraging aesthetic\", \"sunset views\", \"ocean waves\", \"park picnic\",\n",
        "    ],\n",
        "    \"HOME_LIFESTYLE\": [\n",
        "        \"clean girl morning\", \"morning routine\", \"that girl aesthetic\", \"romanticize your life\",\n",
        "        \"slow living\", \"minimalist home\", \"cozy home\", \"candle aesthetic\", \"linen bedding\",\n",
        "        \"morning coffee\", \"kitchen aesthetic\", \"plant corner\", \"vintage decor\", \"home organization\",\n",
        "        \"cleaning motivation\", \"hygge vibes\", \"neutral aesthetic\", \"home cafe\", \"interior design\",\n",
        "        \"vintage finds\",\n",
        "    ],\n",
        "    \"FASHION_STYLE\": [\n",
        "        \"clean girl\", \"coquette aesthetic\", \"balletcore\", \"old money aesthetic\",\n",
        "        \"coastal grandmother\", \"French girl style\", \"capsule wardrobe\", \"minimal wardrobe\",\n",
        "        \"thrifted finds\", \"vintage fashion\", \"outfit inspo\", \"neutral tones\", \"linen clothing\",\n",
        "        \"timeless style\", \"classic pieces\", \"jewelry aesthetic\", \"minimalist jewelry\",\n",
        "        \"vintage accessories\", \"wardrobe organization\", \"fashion archive\", \"faceless selfies\",\n",
        "    ],\n",
        "    \"ART_CULTURE\": [\n",
        "        \"museum aesthetic\", \"art gallery\", \"classical paintings\", \"Renaissance aesthetic\",\n",
        "        \"sculpture garden\", \"art history\", \"vintage portraits\", \"poetry journal\",\n",
        "        \"calligraphy aesthetic\", \"watercolor painting\", \"sketching aesthetic\", \"art studio\",\n",
        "        \"creative process\", \"museum date\", \"gallery wall\", \"art books\", \"painting aesthetic\",\n",
        "        \"drawing aesthetic\", \"vintage art prints\", \"art supplies\", \"classical painting aesthetic\",\n",
        "    ],\n",
        "    \"COFFEE_CAFE\": [\n",
        "        \"coffee shop aesthetic\", \"latte art\", \"espresso bar\", \"cafe hopping\", \"coffee at home\",\n",
        "        \"vintage cafe\", \"European cafe\", \"morning coffee\", \"coffee table books\",\n",
        "        \"cafe study session\", \"iced coffee aesthetic\", \"pastry and coffee\", \"coffee shop reading\",\n",
        "        \"barista aesthetic\", \"pour over coffee\", \"cafe interior\", \"cafe breakfast\", \"coffee date\",\n",
        "        \"local cafe\",\n",
        "    ],\n",
        "    \"PRODUCTIVITY_ORGANIZATION\": [\n",
        "        \"productive day\", \"morning pages\", \"to-do lists\", \"planner aesthetic\", \"digital planning\",\n",
        "        \"desk setup\", \"workspace aesthetic\", \"organization hacks\", \"minimal desk\",\n",
        "        \"calendar planning\", \"goal setting\", \"habit tracking\", \"productivity tips\",\n",
        "        \"time blocking\", \"workspace tour\", \"stationery haul\", \"pen collection\",\n",
        "        \"notebook aesthetic\", \"planning routine\",\n",
        "    ],\n",
        "    \"COZY_COMFORT\": [\n",
        "        \"rainy day aesthetic\", \"cozy corner\", \"blanket fort\", \"reading in bed\", \"candles and books\",\n",
        "        \"autumn vibes\", \"winter cozy\", \"fireplace reading\", \"tea and books\", \"comfort food\",\n",
        "        \"lazy Sunday\", \"sweater weather\", \"soft lighting\", \"warm drinks\", \"comfort shows\",\n",
        "        \"cozy evenings\", \"peaceful morning\", \"quiet moments\", \"self care Sunday\",\n",
        "    ],\n",
        "    \"BEAUTY_SKINCARE\": [\n",
        "        \"clean beauty\", \"skincare routine\", \"morning skincare\", \"glass skin\", \"skincare fridge\",\n",
        "        \"minimal makeup\", \"natural beauty\", \"skincare aesthetic\", \"bathroom organization\",\n",
        "        \"product empties\", \"beauty routine\", \"self care rituals\", \"face masks\", \"gua sha routine\",\n",
        "        \"skincare haul\", \"clean products\", \"bathroom aesthetic\", \"vanity organization\",\n",
        "    ],\n",
        "    \"VINTAGE_NOSTALGIA\": [\n",
        "        \"vintage aesthetic\", \"film photography\", \"old books\", \"antique finds\", \"thrift haul\",\n",
        "        \"vintage camera\", \"retro vibes\", \"analog photography\", \"vintage postcards\",\n",
        "        \"grandmother's house\", \"heirloom pieces\", \"vintage mirrors\", \"antique furniture\",\n",
        "        \"film developing\", \"disposable camera\", \"vintage jewelry\", \"old letters\",\n",
        "        \"family heirlooms\", \"nostalgic moments\",\n",
        "    ],\n",
        "    \"SEASONS_HOLIDAYS\": [\n",
        "        \"autumn aesthetic\", \"fall vibes\", \"pumpkin season\", \"spring flowers\", \"summer aesthetic\",\n",
        "        \"winter wonderland\", \"holiday baking\", \"seasonal decor\", \"changing seasons\",\n",
        "        \"autumn walks\", \"spring cleaning\", \"summer picnic\", \"winter reading\", \"seasonal cooking\",\n",
        "        \"holiday prep\", \"cozy autumn\", \"fresh spring\", \"hot girl summer\", \"winter layers\",\n",
        "    ],\n",
        "    \"JOURNALING_WRITING\": [\n",
        "        \"journaling aesthetic\", \"morning pages\", \"creative writing\", \"poetry writing\",\n",
        "        \"diary aesthetic\", \"vintage journal\", \"writing routine\", \"pen and paper\", \"journal spread\",\n",
        "        \"daily reflection\", \"writing prompts\", \"handwriting aesthetic\", \"journal collection\",\n",
        "        \"creative journaling\", \"writer aesthetic\", \"coffee and writing\", \"notebook collection\",\n",
        "        \"ink and paper\",\n",
        "    ],\n",
        "    \"MUSIC_CREATIVE\": [\n",
        "        \"vinyl collection\", \"record player\", \"music aesthetic\", \"concert aesthetic\", \"indie music\",\n",
        "        \"classical music\", \"piano aesthetic\", \"guitar aesthetic\", \"music journal\", \"album covers\",\n",
        "        \"concert photos\", \"band posters\", \"music room\", \"vintage records\", \"cassette tapes\",\n",
        "        \"music notes\", \"practicing aesthetic\", \"musician life\",\n",
        "    ],\n",
        "    \"COUPLE\": [\n",
        "        \"couple aesthetic\",\n",
        "    ],\n",
        "}\n",
        "\n",
        "def get_all_topics():\n",
        "    \"\"\"Return all topics as a flat list of (category, topic) tuples.\"\"\"\n",
        "    all_topics = []\n",
        "    for category, topics in PINTEREST_TOPICS.items():\n",
        "        for topic in topics:\n",
        "            all_topics.append((category, topic))\n",
        "    return all_topics\n",
        "\n",
        "def get_topics_for_categories(categories):\n",
        "    \"\"\"Return topics for specific categories.\"\"\"\n",
        "    result = []\n",
        "    for category in categories:\n",
        "        if category in PINTEREST_TOPICS:\n",
        "            for topic in PINTEREST_TOPICS[category]:\n",
        "                result.append((category, topic))\n",
        "    return result\n",
        "'''\n",
        "\n",
        "Path('topics.py').write_text(topics_content)\n",
        "print(\"✓ topics.py created\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "config"
      },
      "source": [
        "## 4. Configuration\n",
        "\n",
        "Set your scraping preferences below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "config_cell"
      },
      "outputs": [],
      "source": [
        "# @markdown ### Scraping Configuration\n",
        "\n",
        "# @markdown Categories to scrape (comma-separated or \"ALL\"):\n",
        "CATEGORIES = \"ALL\"  # @param [\"ALL\", \"STUDY_ACADEMIA\", \"FOOD_COOKING\", \"BOOKS_READING\", \"TRAVEL\", \"FITNESS_WELLNESS\", \"NATURE_OUTDOORS\", \"HOME_LIFESTYLE\", \"FASHION_STYLE\", \"ART_CULTURE\", \"COFFEE_CAFE\", \"PRODUCTIVITY_ORGANIZATION\", \"COZY_COMFORT\", \"BEAUTY_SKINCARE\", \"VINTAGE_NOSTALGIA\", \"SEASONS_HOLIDAYS\", \"JOURNALING_WRITING\", \"MUSIC_CREATIVE\", \"COUPLE\"]\n",
        "\n",
        "# @markdown Number of pins per topic:\n",
        "MAX_PINS_PER_TOPIC = 50  # @param {type:\"slider\", min:10, max:200, step:10}\n",
        "\n",
        "# @markdown Google Drive output folder path (must be in your Drive):\n",
        "DRIVE_OUTPUT_PATH = \"/content/drive/MyDrive/PinterestScraper\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown Download images to Drive:\n",
        "DOWNLOAD_IMAGES = True  # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown Number of topics to process in parallel (lower if you encounter issues):\n",
        "MAX_CONCURRENT_TOPICS = 2  # @param {type:\"slider\", min:1, max:5, step:1}\n",
        "\n",
        "# @markdown Run in headless mode (set False to see browser):\n",
        "HEADLESS = True  # @param {type:\"boolean\"}\n",
        "\n",
        "print(f\"\\n✓ Configuration set:\")\n",
        "print(f\"  Categories: {CATEGORIES}\")\n",
        "print(f\"  Max pins per topic: {MAX_PINS_PER_TOPIC}\")\n",
        "print(f\"  Output path: {DRIVE_OUTPUT_PATH}\")\n",
        "print(f\"  Download images: {DOWNLOAD_IMAGES}\")\n",
        "print(f\"  Concurrent topics: {MAX_CONCURRENT_TOPICS}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "run_scraper"
      },
      "source": [
        "## 5. Run the Scraper\n",
        "\n",
        "This will start scraping Pinterest and save everything directly to your Google Drive.\n",
        "\n",
        "**Note:** This will take a long time depending on how many topics you're scraping. You can safely close this tab and check your Google Drive later - the scraper will continue running in the Colab runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scrape_code"
      },
      "outputs": [],
      "source": [
        "# Create and run the scraper\n",
        "scraper_code = '''\n",
        "import asyncio\n",
        "import random\n",
        "import json\n",
        "import logging\n",
        "import hashlib\n",
        "from pathlib import Path\n",
        "from typing import Set, List, Dict, Tuple\n",
        "from datetime import datetime\n",
        "from playwright.async_api import async_playwright\n",
        "import aiohttp\n",
        "\n",
        "from topics import get_all_topics, get_topics_for_categories\n",
        "\n",
        "# Configuration from Colab\n",
        "CONFIG = {\n",
        "    \"categories\": \"''' + CATEGORIES + '''\",\n",
        "    \"max_pins_per_topic\": ''' + str(MAX_PINS_PER_TOPIC) + ''',\n",
        "    \"output_folder\": \"''' + DRIVE_OUTPUT_PATH + '''\",\n",
        "    \"download_images\": ''' + str(DOWNLOAD_IMAGES) + ''',\n",
        "    \"headless\": ''' + str(HEADLESS) + ''',\n",
        "    \"timeout\": 45000,\n",
        "    \"max_concurrent_topics\": ''' + str(MAX_CONCURRENT_TOPICS) + ''',\n",
        "    \"max_concurrent_downloads\": 10,\n",
        "}\n",
        "\n",
        "# NSFW blocklist\n",
        "NSFW_BLOCKLIST = [\n",
        "    \"nude\", \"naked\", \"sexy\", \"hot\", \"adult\", \"porn\", \"xxx\", \"erotic\", \"18+\", \"onlyfans\",\n",
        "    \"bikini\", \"lingerie\", \"booty\", \"ass\", \"tits\", \"boobs\", \"cleavage\", \"thong\", \"nsfw\",\n",
        "    \"sex\", \"topless\", \"underwear\", \"braless\", \"see-through\", \"explicit\", \"fetish\",\n",
        "]\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
        "    datefmt=\"%H:%M:%S\"\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def is_text_safe(title: str, description: str) -> bool:\n",
        "    text = (title + \" \" + description).lower()\n",
        "    return not any(kw in text for kw in NSFW_BLOCKLIST)\n",
        "\n",
        "def get_pin_hash(pin_id: str) -> str:\n",
        "    return hashlib.md5(pin_id.encode()).hexdigest()[:16]\n",
        "\n",
        "async def download_image(session: aiohttp.ClientSession, image_url: str, save_path: Path) -> bool:\n",
        "    try:\n",
        "        async with session.get(image_url, timeout=aiohttp.ClientTimeout(total=30)) as response:\n",
        "            if response.status == 200:\n",
        "                content = await response.read()\n",
        "                save_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "                with open(save_path, \"wb\") as f:\n",
        "                    f.write(content)\n",
        "                return True\n",
        "            return False\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "async def download_images_batch(pins: List[Dict], category: str, topic: str, output_base: Path):\n",
        "    if not CONFIG[\"download_images\"]:\n",
        "        return\n",
        "    images_dir = output_base / category / topic.replace(\" \", \"_\") / \"images\"\n",
        "    images_dir.mkdir(parents=True, exist_ok=True)\n",
        "    semaphore = asyncio.Semaphore(CONFIG[\"max_concurrent_downloads\"])\n",
        "\n",
        "    async def download_with_semaphore(pin: Dict):\n",
        "        async with semaphore:\n",
        "            img_filename = f\"{pin['pin_id']}.jpg\"\n",
        "            img_path = images_dir / img_filename\n",
        "            if not img_path.exists():\n",
        "                img_url = pin[\"image_url\"].replace(\"236x\", \"originals\").replace(\"564x\", \"originals\")\n",
        "                await download_image(asyncio.current_task().session, img_url, img_path)\n",
        "\n",
        "    async with aiohttp.ClientSession() as session:\n",
        "        asyncio.current_task().session = session\n",
        "        tasks = [download_with_semaphore(pin) for pin in pins]\n",
        "        await asyncio.gather(*tasks, return_exceptions=True)\n",
        "\n",
        "async def human_like_scroll(page):\n",
        "    viewport_height = page.viewport_size[\"height\"]\n",
        "    for _ in range(random.randint(2, 5)):\n",
        "        scroll_distance = random.randint(300, viewport_height - 200)\n",
        "        await page.evaluate(f\"window.scrollBy(0, {scroll_distance})\")\n",
        "        await asyncio.sleep(random.uniform(0.8, 2.2))\n",
        "\n",
        "async def random_delay(min_sec: float = 1.8, max_sec: float = 4.2):\n",
        "    await asyncio.sleep(random.uniform(min_sec, max_sec))\n",
        "\n",
        "async def scrape_topic(category: str, topic: str, collected_hashes: Set[str], output_base: Path) -> List[Dict]:\n",
        "    logger.info(f\"Starting: [{category}] {topic}\")\n",
        "    collected_pins = []\n",
        "    try:\n",
        "        async with async_playwright() as p:\n",
        "            browser = await p.chromium.launch(headless=CONFIG[\"headless\"])\n",
        "            context = await browser.new_context(\n",
        "                viewport={\"width\": 1920, \"height\": 1080},\n",
        "                user_agent=\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36\"\n",
        "            )\n",
        "            page = await context.new_page()\n",
        "            search_url = f\"https://www.pinterest.com/search/pins/?q={topic.replace(' ', '%20')}\"\n",
        "            await page.goto(search_url, wait_until=\"domcontentloaded\", timeout=CONFIG[\"timeout\"])\n",
        "\n",
        "            try:\n",
        "                await page.get_by_role(\"button\", name=\"Accept all\").click(timeout=8000)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            last_height = await page.evaluate(\"document.body.scrollHeight\")\n",
        "            scroll_attempts = 0\n",
        "\n",
        "            while len(collected_pins) < CONFIG[\"max_pins_per_topic\"] and scroll_attempts < 50:\n",
        "                await human_like_scroll(page)\n",
        "                await random_delay()\n",
        "\n",
        "                pin_elements = await page.query_selector_all('div[data-test-id=\"pin\"]')\n",
        "\n",
        "                for pin_el in pin_elements:\n",
        "                    if len(collected_pins) >= CONFIG[\"max_pins_per_topic\"]:\n",
        "                        break\n",
        "                    try:\n",
        "                        title_el = await pin_el.query_selector('div[data-test-id=\"pin-title\"]')\n",
        "                        title = await title_el.inner_text() if title_el else \"\"\n",
        "                        desc_el = await pin_el.query_selector('div[data-test-id=\"pin-description\"]')\n",
        "                        description = await desc_el.inner_text() if desc_el else \"\"\n",
        "                        img_el = await pin_el.query_selector('img[src*=\"pinimg.com\"]')\n",
        "                        img_src = await img_el.get_attribute(\"src\") if img_el else None\n",
        "                        link_el = await pin_el.query_selector('a[href*=\"/pin/\"]')\n",
        "                        pin_url = await link_el.get_attribute(\"href\") if link_el else \"\"\n",
        "                        pin_id = pin_url.split(\"/pin/\")[-1].split(\"/\")[0] if pin_url else \"\"\n",
        "\n",
        "                        if img_src and pin_id:\n",
        "                            pin_hash = get_pin_hash(pin_id)\n",
        "                            if pin_hash in collected_hashes:\n",
        "                                continue\n",
        "                            if not is_text_safe(title, description):\n",
        "                                continue\n",
        "\n",
        "                            pin_data = {\n",
        "                                \"pin_id\": pin_id,\n",
        "                                \"title\": title.strip(),\n",
        "                                \"description\": description.strip(),\n",
        "                                \"image_url\": img_src,\n",
        "                                \"category\": category,\n",
        "                                \"topic\": topic,\n",
        "                            }\n",
        "                            collected_pins.append(pin_data)\n",
        "                            collected_hashes.add(pin_hash)\n",
        "                    except:\n",
        "                        continue\n",
        "\n",
        "                new_height = await page.evaluate(\"document.body.scrollHeight\")\n",
        "                if new_height == last_height:\n",
        "                    scroll_attempts += 1\n",
        "                else:\n",
        "                    scroll_attempts = 0\n",
        "                    last_height = new_height\n",
        "\n",
        "            await browser.close()\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error scraping [{category}] {topic}: {e}\")\n",
        "\n",
        "    return collected_pins\n",
        "\n",
        "async def scrape_all():\n",
        "    if CONFIG[\"categories\"].upper() == \"ALL\":\n",
        "        topics_to_scrape = get_all_topics()\n",
        "    else:\n",
        "        category_list = [c.strip().upper().replace(\"/\", \"_\") for c in CONFIG[\"categories\"].split(\",\")]\n",
        "        topics_to_scrape = get_topics_for_categories(category_list)\n",
        "\n",
        "    logger.info(f\"Scraping {len(topics_to_scrape)} topics\")\n",
        "\n",
        "    output_base = Path(CONFIG[\"output_folder\"])\n",
        "    output_base.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    collected_hashes: Set[str] = set()\n",
        "    all_pins = []\n",
        "    completed = 0\n",
        "\n",
        "    semaphore = asyncio.Semaphore(CONFIG[\"max_concurrent_topics\"])\n",
        "\n",
        "    async def scrape_with_limit(category_topic: Tuple[str, str]):\n",
        "        nonlocal completed\n",
        "        category, topic = category_topic\n",
        "        async with semaphore:\n",
        "            pins = await scrape_topic(category, topic, collected_hashes, output_base)\n",
        "            if pins:\n",
        "                topic_dir = output_base / category / topic.replace(\" \", \"_\")\n",
        "                topic_dir.mkdir(parents=True, exist_ok=True)\n",
        "                json_path = topic_dir / f\"{topic.replace(' ', '_')}_pins.json\"\n",
        "                with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                    json.dump(pins, f, indent=2, ensure_ascii=False)\n",
        "                await download_images_batch(pins, category, topic, output_base)\n",
        "                completed += 1\n",
        "                logger.info(f\"Progress: {completed}/{len(topics_to_scrape)} | [{category}] {topic}: {len(pins)} pins\")\n",
        "                all_pins.extend(pins)\n",
        "            await random_delay(3, 8)\n",
        "\n",
        "    tasks = [scrape_with_limit(ct) for ct in topics_to_scrape]\n",
        "    await asyncio.gather(*tasks, return_exceptions=True)\n",
        "\n",
        "    # Save master JSON\n",
        "    master_json = output_base / \"all_pins.json\"\n",
        "    with open(master_json, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(all_pins, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    logger.info(f\"=\"*60)\n",
        "    logger.info(f\"Scraping complete!\")\n",
        "    logger.info(f\"Total pins collected: {len(all_pins)}\")\n",
        "    logger.info(f\"Saved to: {output_base}\")\n",
        "    logger.info(f\"=\"*60)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(scrape_all())\n",
        "'''\n",
        "\n",
        "# Write scraper to file and run\n",
        "Path('scraper.py').write_text(scraper_code)\n",
        "print(\"Starting scraper...\\n\")\n",
        "print(\"This will take a while. You can close this tab and check your Google Drive later.\")\n",
        "print(f\"\\nOutput will be saved to: {DRIVE_OUTPUT_PATH}\\n\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "!python scraper.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "check_progress"
      },
      "source": [
        "## 6. Check Progress\n",
        "\n",
        "Run this cell to see what's been saved to your Google Drive so far:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check_progress_code"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "drive_path = Path(DRIVE_OUTPUT_PATH)\n",
        "\n",
        "if drive_path.exists():\n",
        "    print(f\"Contents of {drive_path}:\\n\")\n",
        "    \n",
        "    # Count categories\n",
        "    categories = [d for d in drive_path.iterdir() if d.is_dir()]\n",
        "    print(f\"Categories found: {len(categories)}\\n\")\n",
        "    \n",
        "    for cat in sorted(categories):\n",
        "        # Count topics and files\n",
        "        topics = [d for d in cat.iterdir() if d.is_dir()]\n",
        "        json_files = list(cat.glob(\"*.json\"))\n",
        "        \n",
        "        # Count images\n",
        "        image_count = 0\n",
        "        for topic in topics:\n",
        "            images_dir = topic / \"images\"\n",
        "            if images_dir.exists():\n",
        "                image_count += len(list(images_dir.glob(\"*.jpg\")))\n",
        "        \n",
        "        print(f\"  {cat.name}: {len(topics)} topics, {image_count} images\")\n",
        "else:\n",
        "    print(f\"Output directory not found yet: {drive_path}\")\n",
        "    print(\"The scraper is still running or hasn't started.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "done"
      },
      "source": [
        "## Done!\n",
        "\n",
        "Your scraped content is saved in Google Drive at:\n",
        "`" + "`/content/drive/MyDrive/PinterestScraper`" + "`\n",
        "\n",
        "You can now:\n",
        "1. Open your Google Drive to browse the downloaded images\n",
        "2. Disconnect and delete this runtime (optional)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
